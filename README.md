ReArch Group Paper Reading List
===============================

 

Seminars
--------

### Spring 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 03.01  | [Training for Multi-resolution Inference Using Reusable Quantization Terms](http://www.eecs.harvard.edu/~htk/publication/2021-asplos-zhang-mcdanel-kung-dong.pdf) | Cong Guo      |           |
| 03.08  | [Toward Efficient Interactions between Python and Native Libraries](https://github.com/usyd-fsalab/ReadingList/blob/main/pdf/asplos21-paper586.pdf) | Yuxian Qiu | |
| 03.15  | [SpAtten: Efficient Natural Language Processing](https://hanlab.mit.edu/projects/spatten/) | Yue Guan | |
| 03.22  | [X-Stream: Edge-centric Graph Processing using Streaming Partitions](https://github.com/bindscha/x-stream) | Zhihui Zhang | |
| 03.29  | [Loop Nested Optimization, Polyhedral Model and Micro-2020 Best Paper (Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data)](https://ieeexplore.ieee.org/document/9251965) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhnxs4_fr_F4Nazto9?e=7sEqQQ) |
| 04.12  | [Defensive Approximation: Securing CNNs using Approximate Computing](https://www.cs.ucr.edu/~nael/pubs/asplos21.pdf) | Yakai Wang | [Related Work](https://ieeexplore.ieee.org/document/6387646) |
| 05.17  | [Commutative Data Reordering: A New Technique to Reduce Data Movement Energy on Sparse Inference Workloads](https://www.osti.gov/servlets/purl/1781776) | Yangjie Zhou | [ISCA 2020](https://jbox.sjtu.edu.cn/l/MFg8AR) |
| 05.31  | [Large Graph Convolutional Network Training with GPU-Oriented Data Communication Architecture](http://vldb.org/pvldb/vol14/p2087-min.pdf) | Zhihui Zhang | [VLDB 2021](https://www.davidmin.net/assets/slides/pyd.pdf) |
| 06.07  | [DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification](https://proceedings.neurips.cc/paper/2021/file/747d3443e319a22747fbb873e8b2f9f2-Paper.pdf) | Yue Guan | [NeurIPS 2021](https://dynamicvit.ivg-research.xyz/) |


### Summer 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 07.14  | [AKG: automatic kernel generation for neural processing units using polyhedral transformations (PLDI 2021)](https://dl.acm.org/doi/pdf/10.1145/3453483.3454106) | Yuxian Qiu | [Slides](https://www.di.ens.fr/~zhaojie/pldi2021-presentation) |
| 07.21  | Floating-Point Format and Quantization for Deep Learning Computation | Cong Guo  |  |
| 07.28  | [P-OPT: Practical Optimal Cache Replacement for Graph Analytics](https://brandonlucia.com/pubs/POPT_HPCA21_CameraReady.pdf) | Yangjie Zhou | [Slides](https://jbox.sjtu.edu.cn/l/u15Q1m) |
| 08.04  | [Rubik: A Hierarchical Architecture for Efficient Graph Neural Network Training](https://ieeexplore.ieee.org/abstract/document/9428002/) | Zhihui Zhang |  |
| 08.11  | [A Useful Tool CKA: Similarity of Neural Network Representations Revisited](https://arxiv.org/abs/1905.00414) and [It's application: Uncovering How Neural Network Representations Vary with Width and Depth](https://arxiv.org/abs/2010.15327) | Zhengyi Li | [Slides](https://jbox.sjtu.edu.cn/l/LFlrY5) |
| 08.18  | [Ansor: Generating High-Performance Tensor Programs for Deep Learning](https://www.usenix.org/conference/osdi20/presentation/zheng) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhtngBEMy48hSSgEEU?e=lnadKt) |

### Fall 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 10.11  | Adaptive numeric type for DNN quantization | Cong Guo | |
| 10.18  | [Compiling Graph Applications for GPUs with GraphIt](https://graphit-lang.org/index) | Yangjie Zhou | [Slides](https://intimeand.space/docs/CGO21-G2.pdf) |
| 11.01  | [TENET: A Framework for Modeling Tensor Dataflow Based on Relation-centric Notation](https://ieeexplore.ieee.org/document/9499903) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhtxk_WtypKJSnhSW0?e=iqLEIh) |
| 11.08  | [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961) | Zhengyi Li | [Slides (code: zdea)](https://pan.baidu.com/s/13dRMZzVwYV4PGcaCAVrZug) | 
| 11.22  | [Dynamic Tensor Rematerialization](https://arxiv.org/abs/2006.09616)  <br /> [Checkmate: Breaking The Memory Wall with Optimal Tensor Rematerialization](https://arxiv.org/abs/2006.09616)| Yue Guan | [Slides](https://www.parasjain.com/projects/20checkmate/checkmate_mlsys_slides.pdf) <br />[Slides](https://marisa.moe/resources/DTR.pptx) | 
| 11.29  | [GraphPulse: An Event-Driven Hardware Accelerator for Asynchronous Graph Processing](https://shafiur.me/publication/rahman-graphpulse-micro-2020/rahman-graphpulse-micro-2020.pdf)| Zhihui Zhang | [Presentation](https://www.youtube.com/watch?v=olhBDSa7xVE)| 
| 12.06  | [CheckFreq: Frequent, Fine-Grained DNN Checkpointing](https://www.usenix.org/system/files/fast21-mohan.pdf)| Guandong Lu | [Slides](https://www.usenix.org/sites/default/files/conference/protected-files/fast21_slides_mohan.pdf)| 
| 12.13  | [PipeDream: generalized pipeline parallelism for DNN training](https://dl.acm.org/doi/10.1145/3341301.3359646)| Runzhe Chen | [Slides](https://jbox.sjtu.edu.cn/l/H1RivF)| 
| 12.20  | [Towards Scalable Distributed Training of Deep Learning on Public Cloud Clusters](https://proceedings.mlsys.org/paper/2021/file/8613985ec49eb8f757ae6439e879bb2a-Paper.pdf)| Yakai Wang | [Slides](https://jbox.sjtu.edu.cn/l/y18DmN)| 

### Spring 2022

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 3.10  | Speculation Attack:  [Meltdown](https://www.usenix.org/conference/usenixsecurity18/presentation/lipp), [Spectre](https://ieeexplore.ieee.org/document/8835233), [Pinned-Loads](https://dl.acm.org/doi/10.1145/3503222.3507724) | Zihan Liu | [Slides](https://www.icloud.com.cn/keynote/0ccG6xZVn7bYlTEwcL42c8UMw#Seminar) |
| 3.24 | SparTA: Deep-Learning Model Sparsity via Tensor-with-Sparsity-Attribute | Yue Guan | |
| 3.31 | ROLLER: Fast and Efficient Tensor Compilation for Deep Learning | Yijia Diao | [Link](https://www.usenix.org/conference/osdi22/presentation/zhu) |
| 4.07 | Adaptable Register File Organization for Vector Processors | Zhihui Zhang | |
| 4.14 | CORTEX: A COMPILER FOR RECURSIVE DEEP LEARNING MODELS | Yangjie Zhou | [Slides](https://slideslive.com/38952764) |
| 4.21 | Zero-Knowledge Succinct Non-Interactive Argument of Knowledge | Shuwen Lu |[Slides](https://summerschool-croatia.cs.ru.nl/2017/slides/Zero%20Knowledge%20Succinct%20Arguments_an%20Introduction.pdf) |
| 5.05 | [Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning](https://arxiv.org/abs/2201.12023) | Runzhe Chen |[Slides](https://jbox.sjtu.edu.cn/l/U1PTfl) |

### Fall 2022
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 9.20  | [ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization](https://arxiv.org/abs/2208.14286) | Cong Guo | [Slides](./Slides/ant_slides.pdf) |
| 9.27  | [X-cache: a modular architecture for domain-specific caches](https://dl.acm.org/doi/10.1145/3470496.3527380) | Zihan Liu | [Slides](https://www.icloud.com.cn/keynote/075L-zhbpPXbrS_En5ISDHUfA#Seminar-2022-09-27) |
| 10.18 | Automatically Discovering  ML Optimizations                                | Yangjie Zhou  | [Slides](https://chips-compilers-mlsys-22.github.io/assets/slides/Zhihao_Jia_MLSys_2022-09-01.pdf) |
| 11.8 | Privacy Preserving Machine Learning--inference                                 | Zhengyi Li  | [Slides](./Slides/PPML.pptx) |
| 11.15 | Dynamic Tensor Compilers | Yijia Diao | [Slides](./Slides/11.15-yijia.pdf) |

### Spring 2023
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 3.30  | JUNO: Algorithm-Hardware Mapping Co-design for Efficient\\Approximate Nearest Neighbour Search in High Dimensional Space | Zihan Liu | |
| 4.6 | [LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale](https://arxiv.org/abs/2208.07339); [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2211.10438); [Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning](https://arxiv.org/abs/2208.11580); [GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED](https://arxiv.org/abs/2210.17323); [SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot](https://arxiv.org/abs/2301.00774); [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602); [Offsite-Tuning: Transfer Learning without Full Model](https://arxiv.org/abs/2302.04870); [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) | Jiaming Tang |[Slides](./Slides/2023.4.6-jiaming.pdf) |
| 4.13 | SMG: Towards Efficient Execution and Adequate Encryption of Private DNN Inference via Secure Micro-Graph                                 | Zhengyi Li  | [Slides](./Slides/Zhengyi_SecGraph.pptx) |
| 5.04 | FlexGen and FlashAttention | Yue Guan  | [Slides](./Slides/23.05.04-yueguan.pptx) |
| 5.11 | Multi-Tenant DNN Inference: Spatial GPU Sharing | Yijia Diao  | [Slides](./Slides/23.05.11-yijia.pdf) |
| 5.25 | [Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion](https://ieeexplore.ieee.org/document/10071018) | Yangjie Zhou | [TVMConf Video](https://www.youtube.com/watch?v=VtWqP_wQX9U) |

### Fall 2023
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 9.21 | GPU Warp Scheduling and Control Code | Weiming Hu | [Slides](./Slides/23.09.21-weiming.pdf) |
| 9.28 | [Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity](https://arxiv.org/abs/2309.10285) | Yue Guan | [Slides](./Slides/23.09.28-yguan.pdf) |
| 10.12 | [Shared SIMD unit: Occamy](https://dl.acm.org/doi/10.1145/3582016.3582046), Two Out-of-Order Commit CPU: [NOREBA](https://dl.acm.org/doi/pdf/10.1145/3445814.3446726) and [Orinoco](https://dl.acm.org/doi/10.1145/3579371.3589046) | Zihan Liu | [Slides](./Slides/23.10.28-zhliu.key) |
| 10.19 | Multitasking on GPU: Preemption | Yijia Diao | [Slides](./Slides/23.10.19-yijia.pdf) |
| 10.26 | [SecretFlow-SPU: A Performant and User-Friendly Framework for Privacy-Preserving Machine Learning](https://www.usenix.org/conference/atc23/presentation/ma) | Zhengyi Li | [Slides](https://www.usenix.org/system/files/atc23_slides_ma.pdf) |
| 11.09 | [Efficient large-scale language model training on GPU clusters using megatron-LM](https://dl.acm.org/doi/10.1145/3458817.3476209); [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](http://arxiv.org/abs/1910.02054); [ZeRO-Offload: Democratizing Billion-Scale Model Training](http://arxiv.org/abs/2101.06840); [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](http://arxiv.org/abs/2104.07857) | Jiale Xu | [Slides](./Slides/23.11.9-jlxu.pptx) |
| 11.16 | [ATOM: LOW-BIT QUANTIZATION FOR EFFICIENT AND ACCURATE LLM SERVING](https://arxiv.org/abs/2310.19102) | Haoyan Zhang | [Slides](./Slides/23.11.16-haoyan.pptx) |
| 12.07 |[WaveScalar](https://ieeexplore.ieee.org/document/1253203);[Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning Workloads](https://ieeexplore.ieee.org/document/9138986)|Gonglin Xu|[Slides](./Slides/12.07-gonglin.pptx)|
| 12.14 |[Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192);[SpecInfer: Accelerating Generative Large Language Model Serving with Speculative Inference and Token Tree Verification](https://arxiv.org/abs/2305.09781);[LLMCad: Fast and Scalable On-device Large Language Model Inference](https://arxiv.org/abs/2309.04255)|Changming Yu|[Slides](./Slides/23.12.14-changming.pdf)|
| 12.28 |[A Framework for Fine-Grained Synchronization of Dependent GPU Kernels](https://arxiv.org/abs/2305.13450);[Fast Fine-Grained Global Synchronization on GPUs](https://dl.acm.org/doi/abs/10.1145/3297858.3304055);[AutoScratch: ML-Optimized Cache Management for Inference-Oriented GPUs](https://proceedings.mlsys.org/paper_files/paper/2023/hash/627b5f83ffa130fb33cb03dafb47a630-Abstract-mlsys2023.html)|Ziyu Huang|[Slides](./Slides/12.29-ziyu_huang.pdf)|

### Spring 2024

| Date  | Paper Title                                                  | Presenter  | Notes                                                        |
| ----- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| 03.21 | Transparent GPU Sharing in Container Clouds for Deep Learning Workloads | Yijia Diao | [Link](https://www.usenix.org/conference/nsdi23/presentation/wu) |



DNN Architecture
----------------

[Link](Architecture/DNNAccelerator.md)

 

Deep Learning Compiler
----------------------

[List Contributed by Zihan Liu](DeepLearningCompiler/DLPaperList.md)

 

Past Architecture Papers
------------------------

[List Contributed by Jingwen Leng](Architecture/PAST.md)

 

MoE Related Papers
------------------------

[List Contributed by Shuwen Lu](MoE/MoE.md)


Reading List From Other Groups
------------------------------

-   [University of Sydney, Future System Architecture
    Lab](https://github.com/usyd-fsalab/ReadingList)
