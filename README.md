ReArch Group Paper Reading List
===============================

Â 

Seminars
--------

### Spring 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 03.01  | [Training for Multi-resolution Inference Using Reusable Quantization Terms](http://www.eecs.harvard.edu/~htk/publication/2021-asplos-zhang-mcdanel-kung-dong.pdf) | Cong Guo      |           |
| 03.08  | [Toward Efficient Interactions between Python and Native Libraries](https://github.com/usyd-fsalab/ReadingList/blob/main/pdf/asplos21-paper586.pdf) | Yuxian Qiu | |
| 03.15  | [SpAtten: Efficient Natural Language Processing](https://hanlab.mit.edu/projects/spatten/) | Yue Guan | |
| 03.22  | [X-Stream: Edge-centric Graph Processing using Streaming Partitions](https://github.com/bindscha/x-stream) | Zhihui Zhang | |
| 03.29  | [Loop Nested Optimization, Polyhedral Model and Micro-2020 Best Paper (Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data)](https://ieeexplore.ieee.org/document/9251965) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhnxs4_fr_F4Nazto9?e=7sEqQQ) |
| 04.12  | [Defensive Approximation: Securing CNNs using Approximate Computing](https://www.cs.ucr.edu/~nael/pubs/asplos21.pdf) | Yakai Wang | [Related Work](https://ieeexplore.ieee.org/document/6387646) |
| 05.17  | [Commutative Data Reordering: A New Technique to Reduce Data Movement Energy on Sparse Inference Workloads](https://www.osti.gov/servlets/purl/1781776) | Yangjie Zhou | [ISCA 2020](https://jbox.sjtu.edu.cn/l/MFg8AR) |
| 05.31  | [Large Graph Convolutional Network Training with GPU-Oriented Data Communication Architecture](http://vldb.org/pvldb/vol14/p2087-min.pdf) | Zhihui Zhang | [VLDB 2021](https://www.davidmin.net/assets/slides/pyd.pdf) |
| 06.07  | [DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification](https://proceedings.neurips.cc/paper/2021/file/747d3443e319a22747fbb873e8b2f9f2-Paper.pdf) | Yue Guan | [NeurIPS 2021](https://dynamicvit.ivg-research.xyz/) |


### Summer 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 07.14  | [AKG: automatic kernel generation for neural processing units using polyhedral transformations (PLDI 2021)](https://dl.acm.org/doi/pdf/10.1145/3453483.3454106) | Yuxian Qiu | [Slides](https://www.di.ens.fr/~zhaojie/pldi2021-presentation) |
| 07.21  | Floating-Point Format and Quantization for Deep Learning Computation | Cong Guo  |  |
| 07.28  | [P-OPT: Practical Optimal Cache Replacement for Graph Analytics](https://brandonlucia.com/pubs/POPT_HPCA21_CameraReady.pdf) | Yangjie Zhou | [Slides](https://jbox.sjtu.edu.cn/l/u15Q1m) |
| 08.04  | [Rubik: A Hierarchical Architecture for Efficient Graph Neural Network Training](https://ieeexplore.ieee.org/abstract/document/9428002/) | Zhihui Zhang |  |
| 08.11  | [A Useful Tool CKA: Similarity of Neural Network Representations Revisited](https://arxiv.org/abs/1905.00414) and [It's application: Uncovering How Neural Network Representations Vary with Width and Depth](https://arxiv.org/abs/2010.15327) | Zhengyi Li | [Slides](https://jbox.sjtu.edu.cn/l/LFlrY5) |
| 08.18  | [Ansor: Generating High-Performance Tensor Programs for Deep Learning](https://www.usenix.org/conference/osdi20/presentation/zheng) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhtngBEMy48hSSgEEU?e=lnadKt) |

### Fall 2021

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 10.11  | Adaptive numeric type for DNN quantization | Cong Guo | |
| 10.18  | [Compiling Graph Applications for GPUs with GraphIt](https://graphit-lang.org/index) | Yangjie Zhou | [Slides](https://intimeand.space/docs/CGO21-G2.pdf) |
| 11.01  | [TENET: A Framework for Modeling Tensor Dataflow Based on Relation-centric Notation](https://ieeexplore.ieee.org/document/9499903) | Zihan Liu | [Slides](https://1drv.ms/p/s!AhjvDaw8hwGhtxk_WtypKJSnhSW0?e=iqLEIh) |
| 11.08  | [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961) | Zhengyi Li | [Slides (code: zdea)](https://pan.baidu.com/s/13dRMZzVwYV4PGcaCAVrZug) | 
| 11.22  | [Dynamic Tensor Rematerialization](https://arxiv.org/abs/2006.09616)  <br /> [Checkmate: Breaking The Memory Wall with Optimal Tensor Rematerialization](https://arxiv.org/abs/2006.09616)| Yue Guan | [Slides](https://www.parasjain.com/projects/20checkmate/checkmate_mlsys_slides.pdf) <br />[Slides](https://marisa.moe/resources/DTR.pptx) | 
| 11.29  | [GraphPulse: An Event-Driven Hardware Accelerator for Asynchronous Graph Processing](https://shafiur.me/publication/rahman-graphpulse-micro-2020/rahman-graphpulse-micro-2020.pdf)| Zhihui Zhang | [Presentation](https://www.youtube.com/watch?v=olhBDSa7xVE)| 
| 12.06  | [CheckFreq: Frequent, Fine-Grained DNN Checkpointing](https://www.usenix.org/system/files/fast21-mohan.pdf)| Guandong Lu | [Slides](https://www.usenix.org/sites/default/files/conference/protected-files/fast21_slides_mohan.pdf)| 
| 12.13  | [PipeDream: generalized pipeline parallelism for DNN training](https://dl.acm.org/doi/10.1145/3341301.3359646)| Runzhe Chen | [Slides](https://jbox.sjtu.edu.cn/l/H1RivF)| 
| 12.20  | [Towards Scalable Distributed Training of Deep Learning on Public Cloud Clusters](https://proceedings.mlsys.org/paper/2021/file/8613985ec49eb8f757ae6439e879bb2a-Paper.pdf)| Yakai Wang | [Slides](https://jbox.sjtu.edu.cn/l/y18DmN)| 

### Spring 2022

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 3.10  | Speculation Attack:  [Meltdown](https://www.usenix.org/conference/usenixsecurity18/presentation/lipp), [Spectre](https://ieeexplore.ieee.org/document/8835233), [Pinned-Loads](https://dl.acm.org/doi/10.1145/3503222.3507724) | Zihan Liu | [Slides](https://www.icloud.com.cn/keynote/0ccG6xZVn7bYlTEwcL42c8UMw#Seminar) |
| 3.24 | SparTA: Deep-Learning Model Sparsity via Tensor-with-Sparsity-Attribute | Yue Guan | |
| 3.31 | ROLLER: Fast and Efficient Tensor Compilation for Deep Learning | Yijia Diao | [Link](https://www.usenix.org/conference/osdi22/presentation/zhu) |
| 4.07 | Adaptable Register File Organization for Vector Processors | Zhihui Zhang | |
| 4.14 | CORTEX: A COMPILER FOR RECURSIVE DEEP LEARNING MODELS | Yangjie Zhou | [Slides](https://slideslive.com/38952764) |
| 4.21 | Zero-Knowledge Succinct Non-Interactive Argument of Knowledge | Shuwen Lu |[Slides](https://summerschool-croatia.cs.ru.nl/2017/slides/Zero%20Knowledge%20Succinct%20Arguments_an%20Introduction.pdf) |
| 5.05 | [Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning](https://arxiv.org/abs/2201.12023) | Runzhe Chen |[Slides](https://jbox.sjtu.edu.cn/l/U1PTfl) |

### Fall 2022
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 9.20  | [ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization](https://arxiv.org/abs/2208.14286) | Cong Guo | [Slides](./Slides/ant_slides.pdf) |
| 9.27  | [X-cache: a modular architecture for domain-specific caches](https://dl.acm.org/doi/10.1145/3470496.3527380) | Zihan Liu | [Slides](https://www.icloud.com.cn/keynote/075L-zhbpPXbrS_En5ISDHUfA#Seminar-2022-09-27) |
| 10.18 | Automatically Discovering  ML Optimizations                                | Yangjie Zhou  | [Slides](https://chips-compilers-mlsys-22.github.io/assets/slides/Zhihao_Jia_MLSys_2022-09-01.pdf) |
| 11.8 | Privacy Preserving Machine Learning--inference                                 | Zhengyi Li  | [Slides](./Slides/22.11.08-zyli-PPML.pptx) |
| 11.15 | Dynamic Tensor Compilers | Yijia Diao | [Slides](./Slides/22.11.15-yijia.pdf) |

### Spring 2023
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 3.30  | JUNO: Algorithm-Hardware Mapping Co-design for Efficient\\Approximate Nearest Neighbour Search in High Dimensional Space | Zihan Liu | |
| 4.6 | [LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale](https://arxiv.org/abs/2208.07339); [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2211.10438); [Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning](https://arxiv.org/abs/2208.11580); [GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED](https://arxiv.org/abs/2210.17323); [SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot](https://arxiv.org/abs/2301.00774); [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602); [Offsite-Tuning: Transfer Learning without Full Model](https://arxiv.org/abs/2302.04870); [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) | Jiaming Tang |[Slides](./Slides/2023.4.6-jiaming.pdf) |
| 4.13 | SMG: Towards Efficient Execution and Adequate Encryption of Private DNN Inference via Secure Micro-Graph                                 | Zhengyi Li  | [Slides](./Slides/23.04.13-zyli-SecGraph.pptx) |
| 5.04 | FlexGen and FlashAttention | Yue Guan  | [Slides](./Slides/23.05.04-yueguan.pptx) |
| 5.11 | Multi-Tenant DNN Inference: Spatial GPU Sharing | Yijia Diao  | [Slides](./Slides/23.05.11-yijia.pdf) |
| 5.25 | [Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion](https://ieeexplore.ieee.org/document/10071018) | Yangjie Zhou | [TVMConf Video](https://www.youtube.com/watch?v=VtWqP_wQX9U) |

### Fall 2023
|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** |
|--------|---------------------------------------------------------------------------|---------------|-----------|
| 9.21 | GPU Warp Scheduling and Control Code | Weiming Hu | [Slides](./Slides/23.09.21-weiming.pdf) |
| 9.28 | [Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity](https://arxiv.org/abs/2309.10285) | Yue Guan | [Slides](./Slides/23.09.28-yguan.pdf) |
| 10.12 | [Shared SIMD unit: Occamy](https://dl.acm.org/doi/10.1145/3582016.3582046), Two Out-of-Order Commit CPU: [NOREBA](https://dl.acm.org/doi/pdf/10.1145/3445814.3446726) and [Orinoco](https://dl.acm.org/doi/10.1145/3579371.3589046) | Zihan Liu | [Slides](./Slides/23.10.28-zhliu.key) |
| 10.19 | Multitasking on GPU: Preemption | Yijia Diao | [Slides](./Slides/23.10.19-yijia.pdf) |
| 10.26 | [SecretFlow-SPU: A Performant and User-Friendly Framework for Privacy-Preserving Machine Learning](https://www.usenix.org/conference/atc23/presentation/ma) | Zhengyi Li | [Slides](https://www.usenix.org/system/files/atc23_slides_ma.pdf) |
| 11.09 | [Efficient large-scale language model training on GPU clusters using megatron-LM](https://dl.acm.org/doi/10.1145/3458817.3476209); [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](http://arxiv.org/abs/1910.02054); [ZeRO-Offload: Democratizing Billion-Scale Model Training](http://arxiv.org/abs/2101.06840); [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](http://arxiv.org/abs/2104.07857) | Jiale Xu | [Slides](./Slides/23.11.9-jlxu.pptx) |
| 11.16 | [ATOM: LOW-BIT QUANTIZATION FOR EFFICIENT AND ACCURATE LLM SERVING](https://arxiv.org/abs/2310.19102) | Haoyan Zhang | [Slides](./Slides/23.11.16-haoyan.pptx) |
| 11.23 | DFU: Dataflow Processing Unit | Renyang Guan | [Slides](./Slides/23.11.23-ryguan.pdf) |
| 12.07 |[WaveScalar](https://ieeexplore.ieee.org/document/1253203);[Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning Workloads](https://ieeexplore.ieee.org/document/9138986)|Gonglin Xu|[Slides](./Slides/12.07-gonglin.pptx)|
| 12.14 |[Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192);[SpecInfer: Accelerating Generative Large Language Model Serving with Speculative Inference and Token Tree Verification](https://arxiv.org/abs/2305.09781);[LLMCad: Fast and Scalable On-device Large Language Model Inference](https://arxiv.org/abs/2309.04255)|Changming Yu|[Slides](./Slides/23.12.14-changming.pdf)|
| 12.28 |[A Framework for Fine-Grained Synchronization of Dependent GPU Kernels](https://arxiv.org/abs/2305.13450);[Fast Fine-Grained Global Synchronization on GPUs](https://dl.acm.org/doi/abs/10.1145/3297858.3304055);[AutoScratch: ML-Optimized Cache Management for Inference-Oriented GPUs](https://proceedings.mlsys.org/paper_files/paper/2023/hash/627b5f83ffa130fb33cb03dafb47a630-Abstract-mlsys2023.html)|Ziyu Huang|[Slides](./Slides/12.29-ziyu_huang.pdf)|

### Spring 2024

| Date  | Paper Title                                                  | Presenter  | Notes                                                        |
| ----- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| 03.14 | LLM Attack and Defense | Zhengyi Li | [Slides](./Slides/24.03.14-zyli-LLM-attack-and-defense.pptx) |
| 03.21 | Transparent GPU Sharing in Container Clouds for Deep Learning Workloads | Yijia Diao | [Link](https://www.usenix.org/conference/nsdi23/presentation/wu) |
| 03.28 | DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving | Shuwen Lu | [Slide](./Slides/2024-03-28-swlu-DistServe.pptx)              |
| 05.09 | [8-bit Transformer Inference and Fine-tuning for Edge Accelerators](https://dl.acm.org/doi/10.1145/3620666.3651368) | Weiming Hu | [Slide](./Slides/2024.05.09-weiming.pdf)                     |

### Fall 2024

| Date  | Paper Title                                                  | Presenter  | Notes                                                        |
| ----- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| 07.26  | TEE-SGX Introduction           | Zhengyi Li  | [Slides](./Slides/24.07.26-zyli-TEE-SGX-introduction.pptx)|
| 08.15  | Accelerating mixture of experts model Inference              | Shuwen Lu  | [Slides](./Slides/24.8.15-swlu.pptx)|
| 08.22  | Accelerating Stable Diffusion-based Video Generation |Yuge Cheng|[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/AcceleratDiT-based_Video_Gen_ChengYuge_0822.pdf)|
| 09.05 | TCP: A Tensor Contraction Processor for AI Workloads | Weiming Hu | [Slides](./Slides/2024.09.05-weiming.pdf) |
| 10.11 | dLoRA: Dynamically Orchestrating Requests and Adapters for LoRA LLM Serving | Haoyan Zhang | [Slides](./Slides/24.10.11-hyzhang.pptx) |
| 10.18 | Dataflow Chips and a Compiler | Renyang Guan | [Slides](./Slides/24.10.18.pdf) |
| 11.01 | ByteCheckpoint A Unified Checkpointing System for Large Foundation Model Development | Gonglin Xu | [Slides](./Slides/2024-11-01-gonglinxu.pptx) |
| 11.15 | Opensora architecture and its computational reuse | Haosong Liu | [Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/24.11.18-HaosongLiu-OpenSora%E5%8F%8A%E5%85%B6%E8%AE%A1%E7%AE%97%E5%A4%8D%E7%94%A8.pptx) |
| 11.22 | LLM Quantization| Wenxuan Miao |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/11.22(1)_20241129122500.pdf)|
| 11.29 | Survey: Large-scale 3DGS| Zheng Liu |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/24%E5%B9%B411%E6%9C%8829%E6%97%A5%20%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5%20large-scale%203DGS_20241209160214.pdf)|
| 12.05 | Enhance Efficiency: 3D Gaussian Splatting for Speed and Memory Optimization| Xiaotong Huang |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/seminar1206_20241209162002.pdf)|
| 12.13 | Stealing Part of a Production Language Model | Zhengyi Li |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/24.12.13-zyli-stealing_pa.rt_of_llm.pptx)|
| 12.20 | Communication-Compute Co-Optimization in Distributed Training | Yijia Diao |[Slides](https://1drv.ms/b/c/1515f4cb2fd61a52/EUsuj5eLXGVEulB87I85-CQBvhQFYX_uDcq0sMl-wT1Z_w)|
| 12.27 | Byte Latent Transformer: Patches Scale Better Than Tokens | Shuyong Bao |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/blt_20241228203002.pdf)|
| 01.03 | Gemini Mapping and Architecture Co-exploration for Large-scale DNN Chiplet Accelerators | Renyang Guan |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/2025.1.3-renyang.pdf)|

### Spring 2025

| Date  | Paper Title                                                  | Presenter  | Notes                                                        |
| ----- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| 01.17 | HybridFlow: A Flexible and Efficient RLHF Framework | Gonglin Xu |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/2025-1-17.pdf)|
| 02.28 | Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion | Ziyu Huang |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/0228%20-%20%E5%89%AF%E6%9C%AC.pdf)|
| 03.14 | Auto-Vectorization in Compilers: Leveraging SIMD for HighPerformance Computing | Shihan Fang |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/3_14%20Shihan%20Faang.pdf)|
| 03.21 | Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention | Xing Ma |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/%E7%BB%84%E4%BC%9A3_20.pdf)|
| 03.28 | Taming Load Balancing in Distributed LLM Training | Jiale Xu |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/Taming%20Load%20Balancing%20in%20Distributed%20LLM%20Training.pdf)|
| 04.11 | SparseAttn for Video Generation | Yulin Sun |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/ReArch%E7%BB%84%E4%BC%9A0411.pdf)|
| 04.18 | Towards End-to-End Optimization of LLM-based Applications with Ayo | Jiawei Huang |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/Ayo.pdf)|
| 04.25 | FSMoE: A Flexible and Scalable Training System for Sparse Mixture-of-Experts Models | Xiaotong Huang |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/Xiaotong%20Huang.pdf)|
| 05.23 | EXION: Exploiting Inter- and Intra-Iteration Output Sparsity for Diffusion Models | Yuge Chen |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/2025_0514_EXION_Exploiting_Output_Sparsity_for_Diffusion_Models.pdf)|
| 05.30 | Modern Programming Model for Writing Kernels on GPUs | Xinhao Luo |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/5.30.pdf)|
| 06.06 | Prefix Sharing LLM Inference and SGLang | Yitong Ding |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/seminar%20ppt%E4%B8%81%E4%B8%80%E6%A1%90.pdf)|
| 06.13 | Ditto: Accelerating Diffusion Model via Temporal Value Similarity CMC: Video Transformer Acceleration via CODEC Assisted Matrix Condensing | Haosong Liu |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/Seminar6.12_%E5%88%98%E6%98%8A%E5%87%87.pdf)|
| 06.27 | Speeding up LLM and GEMM | Wenxuan Miao |[Slides](https://github.com/SJTU-ReArch-Group/Paper-Reading-List/blob/main/Slides/seminar6.27.pdf)|
| 07.25 | Modeling and Simulation | Weiming Hu |[Slides](./Slides/2025-07-25-Modeling-and-Simulation-WeimingHu.pdf)|





DNN Architecture
----------------

[Link](Architecture/DNNAccelerator.md)

Â 

Deep Learning Compiler
----------------------

[List Contributed by Zihan Liu](DeepLearningCompiler/DLPaperList.md)

Â 

Past Architecture Papers
------------------------

[List Contributed by Jingwen Leng](Architecture/PAST.md)

Â 

MoE Related Papers
------------------------

[List Contributed by Shuwen Lu](MoE/MoE.md)

## Quantization, Data Type, Compression, Acceleration

[List Contributed by Weiming Hu](Quantization-DataType-Compression-Acceleration/Quantization_paper_list.md)


Reading List From Other Groups
------------------------------

-   [University of Sydney, Future System Architecture
    Lab](https://github.com/usyd-fsalab/ReadingList)
