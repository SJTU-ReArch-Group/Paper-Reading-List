Papers
------------------------

Contributed by Weiming Hu

### Data Type

| Conf.     | **Title**                                                    | **Key Words**                               |
| --------- | ------------------------------------------------------------ | ------------------------------------------- |
| ASPLOS'24 | 8-bit Transformer Inference and Fine-tuning for Edge Accelerators | Posit8 and FP8                              |
| DAC'24    | Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference | Posit                                       |
| ICLR'24   | Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference | Propose BSFP                                |
| NIPS'24   | QLoRA: Efficient Finetuning of Quantized LLMs                | Propose NormalFloat4                        |
| ISCA'23   | With Shared Microexponents, A Little Shifting Goes a Long Way | Microsoft MX-FP (two-level shared exponent) |
| arXiv'23  | Microscaling Data Formats for Deep Learning                  | Explore MXFP4, 6, 8                         |
| MICRO'22  | ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization | Adaptive data type, propose Flint           |
| HPCA'22   | FAST: DNN Training Under Variable Precision Block Floating Point with Stochastic Rounding | Use BFP in training                         |
| ICML'22   | Be Like Water: Adaptive Floating Point for Machine Learning  | Adaptive floating point                     |
| NIPS'20   | Pushing the Limits of Narrow Precision Inferencing at Cloud Scale with Microsoft Floating Point | First propose MSFP                          |



